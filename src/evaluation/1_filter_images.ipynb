{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of this notebook is to create the database and tables for the metadata of the dataset\n",
    "# This is necessary to be able to query the data more efficiently compared to the current method of reading the data from a large json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from collections import defaultdict, Counter\n",
    "from enum import IntEnum\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=6.95s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Load the COCO dataset for ground truths\n",
    "cocoGt = COCO('Objects365/test/zhiyuan_objv2_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count categories in each image\n",
    "if cocoGt is not None:\n",
    "    # Create a dictionary to count category occurrences per image\n",
    "    img_obj = defaultdict(Counter)\n",
    "\n",
    "    # Utilize the imgToAnns property to access annotations for each image\n",
    "    for img_id, anns in cocoGt.imgToAnns.items():\n",
    "        # Access all annotations for the current image\n",
    "        for ann in anns:\n",
    "            # Increment the count for this category\n",
    "            img_obj[img_id][ann['category_id']] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     filtered_anns[img_id] \u001b[38;5;241m=\u001b[39m cnt \u001b[38;5;66;03m# 1-3 people and 1-3 dogs and no other animals\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPERSON] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cnt[o365_cat\u001b[38;5;241m.\u001b[39mCAT] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cnt[o365_cat\u001b[38;5;241m.\u001b[39mDOG] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPIGEON] \u001b[38;5;241m+\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPARROT] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     filtered_anns[img_id] \u001b[38;5;241m=\u001b[39m \u001b[43mcnt\u001b[49m \u001b[38;5;66;03m# 1-3 people and 1-3 birds and no other animals\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPERSON] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mCAT] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mDOG] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (cnt[o365_cat\u001b[38;5;241m.\u001b[39mPIGEON] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPARROT] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     34\u001b[0m     filtered_anns[img_id] \u001b[38;5;241m=\u001b[39m cnt \u001b[38;5;66;03m# 1-3 cats and 1-3 dogs and no other animals\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     filtered_anns[img_id] \u001b[38;5;241m=\u001b[39m cnt \u001b[38;5;66;03m# 1-3 people and 1-3 dogs and no other animals\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPERSON] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cnt[o365_cat\u001b[38;5;241m.\u001b[39mCAT] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cnt[o365_cat\u001b[38;5;241m.\u001b[39mDOG] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPIGEON] \u001b[38;5;241m+\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPARROT] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     filtered_anns[img_id] \u001b[38;5;241m=\u001b[39m \u001b[43mcnt\u001b[49m \u001b[38;5;66;03m# 1-3 people and 1-3 birds and no other animals\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPERSON] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mCAT] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m cnt[o365_cat\u001b[38;5;241m.\u001b[39mDOG] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (cnt[o365_cat\u001b[38;5;241m.\u001b[39mPIGEON] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cnt[o365_cat\u001b[38;5;241m.\u001b[39mPARROT] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     34\u001b[0m     filtered_anns[img_id] \u001b[38;5;241m=\u001b[39m cnt \u001b[38;5;66;03m# 1-3 cats and 1-3 dogs and no other animals\u001b[39;00m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.smartcam/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/.smartcam/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Enumerate the Objects365 categories\n",
    "class o365_cat(IntEnum):\n",
    "    PERSON = 1\n",
    "    CAT = 140\n",
    "    DOG = 93\n",
    "    PIGEON = 165\n",
    "    PARROT = 320\n",
    "\n",
    "# Filter the images based on the number of objects in each category\n",
    "filtered_anns = dict()\n",
    "for img_id, cnt in img_obj.items():\n",
    "    # Skip images with more than 25 objects\n",
    "    if sum(cnt.values()) > 25:\n",
    "        continue\n",
    "    \n",
    "    # Single-element combinations\n",
    "    if 1 < cnt[o365_cat.PERSON] <= 3 and cnt[o365_cat.CAT] == 0 and cnt[o365_cat.DOG] == 0 and (cnt[o365_cat.PIGEON] == 0 and cnt[o365_cat.PARROT] == 0):\n",
    "        filtered_anns[img_id] = cnt # 1-3 people and no animals\n",
    "    elif cnt[o365_cat.PERSON] == 0 and 1 < cnt[o365_cat.CAT] <= 3 and cnt[o365_cat.DOG] == 0 and (cnt[o365_cat.PIGEON] == 0 and cnt[o365_cat.PARROT] == 0):\n",
    "        filtered_anns[img_id] = cnt # 1-3 cats and no other animals\n",
    "    elif cnt[o365_cat.PERSON] == 0 and cnt[o365_cat.CAT] == 0 and 1 < cnt[o365_cat.DOG] <= 3 and (cnt[o365_cat.PIGEON] == 0 and cnt[o365_cat.PARROT] == 0):\n",
    "        filtered_anns[img_id] = cnt # 1-3 dogs and no other animals\n",
    "    elif cnt[o365_cat.PERSON] == 0 and cnt[o365_cat.CAT] == 0 and cnt[o365_cat.DOG] == 0 and 1 < cnt[o365_cat.PIGEON] + cnt[o365_cat.PARROT] <= 3:\n",
    "        filtered_anns[img_id] = cnt # 1-3 birds and no other animals\n",
    "    \n",
    "    # Two-element combinations\n",
    "    elif 1 < cnt[o365_cat.PERSON] <= 3 and 1 < cnt[o365_cat.CAT] <= 3 and cnt[o365_cat.DOG] == 0 and (cnt[o365_cat.PIGEON] == 0 and cnt[o365_cat.PARROT] == 0):\n",
    "        filtered_anns[img_id] = cnt # 1-3 people and 1-3 cats and no other animals\n",
    "    elif 1 < cnt[o365_cat.PERSON] <= 3 and cnt[o365_cat.CAT] == 0 and 1 < cnt[o365_cat.DOG] <= 3 and (cnt[o365_cat.PIGEON] == 0 and cnt[o365_cat.PARROT] == 0):\n",
    "        filtered_anns[img_id] = cnt # 1-3 people and 1-3 dogs and no other animals\n",
    "    elif 1 < cnt[o365_cat.PERSON] <= 3 and cnt[o365_cat.CAT] == 0 and cnt[o365_cat.DOG] == 0 and 1 < cnt[o365_cat.PIGEON] + cnt[o365_cat.PARROT] <= 3:\n",
    "        filtered_anns[img_id] = cnt # 1-3 people and 1-3 birds and no other animals\n",
    "    elif cnt[o365_cat.PERSON] == 0 and 1 < cnt[o365_cat.CAT] <= 3 and 1 < cnt[o365_cat.DOG] <= 3 and (cnt[o365_cat.PIGEON] == 0 and cnt[o365_cat.PARROT] == 0):\n",
    "        filtered_anns[img_id] = cnt # 1-3 cats and 1-3 dogs and no other animals\n",
    "    elif cnt[o365_cat.PERSON] == 0 and 1 < cnt[o365_cat.CAT] <= 3 and cnt[o365_cat.DOG] == 0 and 1 < cnt[o365_cat.PIGEON] + cnt[o365_cat.PARROT] <= 3:\n",
    "        filtered_anns[img_id] = cnt # 1-3 cats and 1-3 birds and no other animals\n",
    "    elif cnt[o365_cat.PERSON] == 0 and cnt[o365_cat.CAT] == 0 and 1 < cnt[o365_cat.DOG] <= 3 and 1 < cnt[o365_cat.PIGEON] + cnt[o365_cat.PARROT] <= 3:\n",
    "        filtered_anns[img_id] = cnt # 1-3 dogs and 1-3 birds and no other animals\n",
    "    \n",
    "    # Three-element combinations\n",
    "    elif 1 < cnt[o365_cat.PERSON] <= 3 and 1 < cnt[o365_cat.CAT] <= 3 and 1 < cnt[o365_cat.DOG] <= 3 and (cnt[o365_cat.PIGEON] == 0 and cnt[o365_cat.PARROT] == 0):\n",
    "        filtered_anns[img_id] = cnt # 1-3 people and 1-3 cats and 1-3 dogs and no other animals\n",
    "    elif 1 < cnt[o365_cat.PERSON] <= 3 and 1 < cnt[o365_cat.CAT] <= 3 and cnt[o365_cat.DOG] == 0 and 1 < cnt[o365_cat.PIGEON] + cnt[o365_cat.PARROT] <= 3:\n",
    "        filtered_anns[img_id] = cnt # 1-3 people and 1-3 cats and 1-3 birds and no other animals\n",
    "    elif 1 < cnt[o365_cat.PERSON] <= 3 and cnt[o365_cat.CAT] == 0 and 1 < cnt[o365_cat.DOG] <= 3 and 1 < cnt[o365_cat.PIGEON] + cnt[o365_cat.PARROT] <= 3:\n",
    "        filtered_anns[img_id] = cnt # 1-3 people and 1-3 dogs and 1-3 birds and no other animals\n",
    "    elif cnt[o365_cat.PERSON] == 0 and 1 < cnt[o365_cat.CAT] <= 3 and 1 < cnt[o365_cat.DOG] <= 3 and 1 < cnt[o365_cat.PIGEON] + cnt[o365_cat.PARROT] <= 3:\n",
    "        filtered_anns[img_id] = cnt # 1-3 cats and 1-3 dogs and 1-3 birds and no other animals\n",
    "    \n",
    "    # Four-element combinations\n",
    "    elif 1 < cnt[o365_cat.PERSON] <= 3 and 1 < cnt[o365_cat.CAT] <= 3 and 1 < cnt[o365_cat.DOG] <= 3 and 1 < cnt[o365_cat.PIGEON] + cnt[o365_cat.PARROT] <= 3:\n",
    "        filtered_anns[img_id] = cnt # 1-3 people and 1-3 cats and 1-3 dogs and 1-3 birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate the COCO categories\n",
    "class coco_cat(IntEnum):\n",
    "    PERSON = 0\n",
    "    CAT = 15\n",
    "    DOG = 16\n",
    "    BIRD = 14\n",
    "\n",
    "# Convert the filtered annotations to COCO format\n",
    "filtered_coco = {\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': []\n",
    "}\n",
    "\n",
    "for img_id, cnt in filtered_anns.items():\n",
    "    # Access the annotations for the current image\n",
    "    anns = cocoGt.imgToAnns[img_id]\n",
    "\n",
    "    # Check for 'iscrowd' flag in any annotations; skip to next image if found\n",
    "    if any(ann.get('iscrowd', 0) == 1 for ann in anns if ann['category_id'] in [cat.value for cat in o365_cat]):\n",
    "        continue\n",
    "\n",
    "    for ann in anns:\n",
    "        # Check if the current annotation is in the filtered list\n",
    "        if ann['category_id'] in [cat.value for cat in o365_cat]:\n",
    "            # Create a new annotation for the current image\n",
    "            new_ann = ann.copy()\n",
    "            match new_ann['category_id']:\n",
    "                case o365_cat.PERSON:\n",
    "                    new_ann['category_id'] = coco_cat.PERSON\n",
    "                case o365_cat.CAT:\n",
    "                    new_ann['category_id'] = coco_cat.CAT\n",
    "                case o365_cat.DOG:\n",
    "                    new_ann['category_id'] = coco_cat.DOG\n",
    "                case o365_cat.PIGEON:\n",
    "                    new_ann['category_id'] = coco_cat.BIRD\n",
    "                case o365_cat.PARROT:\n",
    "                    new_ann['category_id'] = coco_cat.BIRD\n",
    "            filtered_coco['annotations'].append(new_ann)\n",
    "\n",
    "    # Add image info to the filtered COCO dataset\n",
    "    filtered_coco['images'].append(cocoGt.imgs[img_id])\n",
    "    \n",
    "# Add the COCO categories to the filtered COCO dataset\n",
    "filtered_coco['categories'].append({\n",
    "    'id': coco_cat.PERSON,\n",
    "    'name': 'person',\n",
    "    'supercategory': 'person'\n",
    "})\n",
    "filtered_coco['categories'].append({\n",
    "    'id': coco_cat.CAT,\n",
    "    'name': 'cat',\n",
    "    'supercategory': 'animal'\n",
    "})\n",
    "filtered_coco['categories'].append({\n",
    "    'id': coco_cat.DOG,\n",
    "    'name': 'dog',\n",
    "    'supercategory': 'animal'\n",
    "})\n",
    "filtered_coco['categories'].append({\n",
    "    'id': coco_cat.BIRD,\n",
    "    'name': 'bird',\n",
    "    'supercategory': 'animal'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: 38821\n",
      "Annotations: 93127\n",
      "Categories: 4\n"
     ]
    }
   ],
   "source": [
    "with open('Objects365/test/filtered_data_coco.json', 'w') as f:\n",
    "    json.dump(filtered_coco, f)\n",
    "\n",
    "print(f\"Images: {len(filtered_coco['images'])}\")\n",
    "print(f\"Annotations: {len(filtered_coco['annotations'])}\")\n",
    "print(f\"Categories: {len(filtered_coco['categories'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".smartcam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
