{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from object_detector import ObjectDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"efficientdet-lite4\": {\n",
    "        \"model_path\": \"../../models/efficientdet-lite/efficientdet-lite4-detection-default.tflite\",\n",
    "        \"input_width\": 640,\n",
    "        \"input_height\": 640,\n",
    "        \"classes_path\": \"../../data/coco-efficientdet.names\",\n",
    "        \"is_yolo\": False\n",
    "    },\n",
    "    \"efficientdet-lite3\": {\n",
    "        \"model_path\": \"../../models/efficientdet-lite/efficientdet-lite3-detection-default.tflite\",\n",
    "        \"input_width\": 512,\n",
    "        \"input_height\": 512,\n",
    "        \"classes_path\": \"../../data/coco-efficientdet.names\",\n",
    "        \"is_yolo\": False\n",
    "    },\n",
    "    \"efficientdet-lite2\": {\n",
    "        \"model_path\": \"../../models/efficientdet-lite/efficientdet-lite2-detection-default.tflite\",\n",
    "        \"input_width\": 448,\n",
    "        \"input_height\": 448,\n",
    "        \"classes_path\": \"../../data/coco-efficientdet.names\",\n",
    "        \"is_yolo\": False\n",
    "    },\n",
    "    \"efficientdet-lite1\": {\n",
    "        \"model_path\": \"../../models/efficientdet-lite/efficientdet-lite1-detection-default.tflite\",\n",
    "        \"input_width\": 384,\n",
    "        \"input_height\": 384,\n",
    "        \"classes_path\": \"../../data/coco-efficientdet.names\",\n",
    "        \"is_yolo\": False\n",
    "    },\n",
    "    \"ssd-mobilenet-v1\": {\n",
    "        \"model_path\": \"../../models/mobilenetv1/ssd-mobilenet-v1-default.tflite\",\n",
    "        \"input_width\": 300,\n",
    "        \"input_height\": 300,\n",
    "        \"classes_path\": \"../../data/coco-efficientdet.names\",\n",
    "        \"is_yolo\": False\n",
    "    },\n",
    "    \"yolov5-small\": {\n",
    "        \"model_path\": \"../../models/yolov5-small/yolov5-small.tflite\",\n",
    "        \"input_width\": 320,\n",
    "        \"input_height\": 320,\n",
    "        \"classes_path\": \"../../data/coco.names\",\n",
    "        \"is_yolo\": True\n",
    "    },\n",
    "    \"yolov5-nano\": {\n",
    "        \"model_path\": \"../../models/yolov5/yolov5n-int8.tflite\",\n",
    "        \"input_width\": 320,\n",
    "        \"input_height\": 320,\n",
    "        \"classes_path\": \"../../data/coco.names\",\n",
    "        \"is_yolo\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "CURRENT_MODEL = model_config[\"yolov5-nano\"]\n",
    "\n",
    "object_detector = ObjectDetector(\n",
    "    model_path=CURRENT_MODEL[\"model_path\"],\n",
    "    input_width=CURRENT_MODEL[\"input_width\"],\n",
    "    input_height=CURRENT_MODEL[\"input_height\"],\n",
    "    classes_path=CURRENT_MODEL[\"classes_path\"],\n",
    "    is_yolo=CURRENT_MODEL[\"is_yolo\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 320 but expected 3 for dimension 1 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IS_YOLO:\n\u001b[1;32m     21\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(frame_resized, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m---> 23\u001b[0m detected_objects, processing_time \u001b[38;5;241m=\u001b[39m \u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_height\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m total_processing_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m processing_time\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Store the detection results\u001b[39;00m\n",
      "File \u001b[0;32m~/Yandex.Disk/CM3070_FP/code/src/evaluation/object_detector.py:265\u001b[0m, in \u001b[0;36mObjectDetector.process_frame\u001b[0;34m(self, frame, frame_width, frame_height, threshold)\u001b[0m\n\u001b[1;32m    262\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Set the input tensor and invoke the interpreter\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_details\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39minvoke()\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Retrieve output tensors and process the detections\u001b[39;00m\n",
      "File \u001b[0;32m~/.smartcam/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:720\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[0;34m(self, tensor_index, value)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[1;32m    705\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \n\u001b[1;32m    707\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 720\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 320 but expected 3 for dimension 1 of input 0."
     ]
    }
   ],
   "source": [
    "with open('Objects365/test/filtered_data_coco.json', 'r') as f:\n",
    "    ds = json.load(f)\n",
    "\n",
    "# Store COCO detection results\n",
    "detection_results = []\n",
    "\n",
    "ann_id = 0\n",
    "\n",
    "total_processing_time = 0\n",
    "\n",
    "# filter specific image\n",
    "# ds[\"images\"] = [d for d in ds[\"images\"] if d[\"id\"] == 684819]\n",
    "\n",
    "for i, img in enumerate(ds[\"images\"]):\n",
    "    # Read the frame and resize it\n",
    "    frame = cv2.imread(f\"./Objects365/test/full-ds/{img['file_name']}\")\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    frame_resized = cv2.resize(frame, (CURRENT_MODEL[\"input_width\"], CURRENT_MODEL[\"input_height\"]))\n",
    "    input_data = np.expand_dims(frame_resized, axis=0)\n",
    "    if CURRENT_MODEL[\"is_yolo\"]:\n",
    "        input_data = np.expand_dims(frame_resized, axis=0).astype(np.float32) / 255.0\n",
    "\n",
    "    detected_objects, processing_time = object_detector.process_frame(frame=input_data, frame_width=frame_width, frame_height=frame_height)\n",
    "    total_processing_time += processing_time\n",
    "\n",
    "    # Store the detection results\n",
    "    for obj in detected_objects:\n",
    "        ann_id += 1\n",
    "        detection_results.append({\n",
    "            \"image_id\": img[\"id\"],\n",
    "            \"category_id\": int(obj.category_id),\n",
    "            \"bbox\": list(obj.bbox),\n",
    "            \"score\": float(obj.confidence)\n",
    "        })\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(f\"{i}/{len(ds['images'])}: {total_processing_time / (i + 1)}, {1 / (total_processing_time / (i + 1))}\")\n",
    "\n",
    "    # annotated_frame = object_detector.draw_frame_bounding_boxes(frame, detected_objects)\n",
    "\n",
    "    # cv2.imshow('Object Detection', annotated_frame)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "# Save the detection results\n",
    "with open('./Objects365/test/yolov5n-int8.json', 'w') as f:\n",
    "    json.dump(detection_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".smartcam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
